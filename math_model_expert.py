"""
[å·²å¼ƒç”¨] å†å²ç‰ˆæœ¬çš„å¤šä¸“å®¶å¼•æ“å®ç°ï¼ˆä¿ç•™ä½œå‚è€ƒï¼‰

å½“å‰é¡¹ç›®çš„ AI è°ƒåº¦å·²æ‹†åˆ†ä¸º 3 ä¸ªç‹¬ç«‹åº•å±‚å¼•æ“æ–‡ä»¶ï¼š
- engine_report.pyï¼šäº”é˜¶æ®µæŠ¥å‘Šç”Ÿæˆå¼•æ“ï¼ˆå¤šä¸“å®¶æ··åˆ-æŠ¥å‘Šç‰ˆï¼‰
- engine_agent_single.pyï¼šå•æ¨¡å‹ Agent å¼•æ“
- engine_agent_multi.pyï¼šå¤šä¸“å®¶æ··åˆ Agent å¼•æ“

æ³¨æ„ï¼šbackend.py å½“å‰ä¸å†å¼•ç”¨æœ¬æ–‡ä»¶ã€‚
"""

import requests
import re
import json
import time

# --- è¾…åŠ©å·¥å…·ï¼šé²æ£’çš„ JSON è§£æå™¨ ---
def extract_and_parse_json(text):
    """
    ä» LLM çš„å›å¤ä¸­æå–å¹¶è§£æ JSONã€‚
    æ”¯æŒå¤„ç† ```json ... ``` åŒ…è£¹çš„æƒ…å†µï¼Œä»¥åŠä¸è§„èŒƒçš„æ ¼å¼ã€‚
    """
    try:
        # 1. å°è¯•ç›´æ¥è§£æ
        return json.loads(text)
    except:
        pass

    try:
        # 2. å°è¯•æå–ä»£ç å—ä¸­çš„ JSON
        match = re.search(r"```json(.*?)```", text, re.DOTALL)
        if match:
            return json.loads(match.group(1).strip())
        
        # 3. å°è¯•æå–å¤§æ‹¬å· {} ä¹‹é—´çš„å†…å®¹
        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            return json.loads(match.group(0).strip())
    except:
        pass
    
    return None

# --- æç¤ºè¯åº“ (Radarm Engine) ---
PROMPTS = {
    "planner": """
    ä½ æ˜¯ä¸€åã€æ•°å­¦å»ºæ¨¡æ¶æ„å¸ˆã€‘ã€‚
    ç”¨æˆ·é—®é¢˜ï¼š{user_query}
    æ•°æ®æ¦‚å†µï¼š{data_context}
    {feedback_context}
    
    è¯·è¾“å‡ºè¯¦ç»†çš„åˆ†æè“å›¾ã€‚
    è¦æ±‚ï¼š
    1. é€»è¾‘ä¸¥å¯†ï¼Œåˆ†ä¸ºï¼šé¢„å¤„ç† -> æ¨¡å‹é€‰æ‹© -> æ±‚è§£ -> éªŒè¯ã€‚
    2. æ˜ç¡®æ¯ä¸€æ­¥ç”¨åˆ°çš„å…·ä½“ç®—æ³•ï¼ˆå¦‚ï¼šä½¿ç”¨éšæœºæ£®æ—å¡«è¡¥ç¼ºå¤±å€¼ï¼Œä½¿ç”¨ ARIMA é¢„æµ‹ï¼‰ã€‚
    3. ä¸è¦å†™ä»£ç ï¼Œåªå†™è®¡åˆ’ã€‚
    """,

    "executor": """
    ä½ æ˜¯ä¸€åã€å»ºæ¨¡ç¨‹åºå‘˜ã€‘ã€‚
    
    ã€æ¶æ„å¸ˆè“å›¾ã€‘
    {plan}
    
    ã€æ•°æ®æ¦‚å†µã€‘
    {data_context}
    
    ã€å·¥å…·ç®±ã€‘
    1. pandas (pd), numpy (np), matplotlib.pyplot (plt), seaborn (sns)
    2. æœºå™¨å­¦ä¹ : `ml.run(df, target='...', task='regression'/'classification'/'clustering', k=...)`
    
    ã€ä»»åŠ¡ã€‘
    ç¼–å†™ Python ä»£ç å®ç°è“å›¾ã€‚
    1. å¿…é¡»å°†æœ€ç»ˆç»“è®ºèµ‹å€¼ç»™å˜é‡ `result`ã€‚
    2. ç»˜å›¾ä¸è¦ä½¿ç”¨ `plt.show()`ã€‚
    3. æ³¨æ„æ•°æ®ç±»å‹ï¼Œé‡åˆ° NaN è¯·å…ˆå¤„ç†ã€‚
    
    ä»…è¾“å‡º ```python ä»£ç å—ã€‚
    """,

    "verifier": """
    ä½ æ˜¯ä¸€åã€å»ºæ¨¡è¯„å®¡ã€‘ï¼ˆé“é¢æ— ç§ï¼‰ã€‚
    
    ã€æ¶æ„å¸ˆè“å›¾ã€‘
    {plan}
    
    ã€ç¨‹åºå‘˜ä»£ç ã€‘
    {code}
    
    ã€è¿è¡Œç»“æœã€‘
    {execution_result}
    
    ã€å®¡æŸ¥çº¢çº¿ - è¿åä»»ä¸€æ¡å¿…é¡»åˆ¤ FAILã€‘
    1. âŒ **ä»£ç æŠ¥é”™**ï¼šç»“æœä¸­åŒ…å« "Error", "Traceback", "Exception"ã€‚
    2. âŒ **ç»“æœä¸ºç©º**ï¼šç»“æœæ˜¯ "None" æˆ–ç©ºå­—ç¬¦ä¸²ã€‚
    3. âŒ **å›¾è¡¨ç¼ºå¤±**ï¼šå¦‚æœè“å›¾è¦æ±‚ç”»å›¾ä½†ä»£ç æ²¡ç”»ï¼ˆæœªè°ƒç”¨ pltï¼‰ã€‚
    4. âŒ **åç¦»è“å›¾**ï¼šæœªå®ç°è“å›¾ä¸­çš„æ ¸å¿ƒç®—æ³•ã€‚
    
    è¯·è¾“å‡ºæ ‡å‡† JSONï¼ˆä¸¥ç¦ Markdownï¼‰ï¼š
    {{
        "status": "PASS" æˆ– "FAIL",
        "reason": "é€šè¿‡çš„ç†ç”±æˆ–å¤±è´¥çš„å…·ä½“åŸå› ï¼ˆå¦‚ï¼šç¬¬Nè¡Œä»£ç æŠ¥é”™ï¼‰",
        "suggestion": "ç»™ç¨‹åºå‘˜çš„å…·ä½“ä¿®å¤å»ºè®®ï¼ˆå¦‚æœæ˜¯æŠ¥é”™ï¼Œè¯·æä¾›ä¿®å¤åçš„ä»£ç ç‰‡æ®µæ€è·¯ï¼‰"
    }}
    """
}

REPORT_PROMPTS = {
    "architect": """
    ä½ æ˜¯ä¸€åã€èµ„æ·±å­¦æœ¯é¡¾é—®ã€‘ã€‚
    æ•°æ®ä¿¡æ¯ï¼š{data_info}
    
    è¯·è®¾è®¡ä¸€ä»½ã€Šæ•°å­¦å»ºæ¨¡åˆ†ææŠ¥å‘Šã€‹çš„å¤§çº²ã€‚
    åŒ…å«ï¼šæ‘˜è¦ã€é—®é¢˜é‡è¿°ã€æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å‡è®¾ã€å»ºæ¨¡æ±‚è§£ã€ç»“è®ºä¸å»ºè®®ã€‚
    è¾“å‡ºæ ¼å¼ï¼šMarkdown åˆ—è¡¨ã€‚
    """,

    "writer": """
    ä½ æ˜¯ä¸€åã€ä¸“ä¸šè®ºæ–‡æ’°å†™äººã€‘ã€‚
    å¤§çº²ï¼š
    {outline}
    
    ç»Ÿè®¡æ‘˜è¦ï¼š
    {data_desc}
    
    ã€å®¡ç¨¿äººåé¦ˆï¼ˆå¦‚æœæœ‰ï¼‰ã€‘
    {feedback}
    
    è¯·æ’°å†™/ä¿®æ”¹åˆ†ææŠ¥å‘Šã€‚
    è¦æ±‚ï¼š
    1. å­¦æœ¯ä¸¥è°¨ï¼ŒMarkdown æ ¼å¼ã€‚
    2. å¿…é¡»å¼•ç”¨ç»Ÿè®¡æ‘˜è¦ä¸­çš„å…·ä½“æ•°å­—ï¼ˆå¦‚å‡å€¼ã€ç›¸å…³ç³»æ•°ï¼‰ã€‚
    3. è¯­è¨€å®¢è§‚ï¼Œé¿å…å£è¯­ã€‚
    """,

    "reviewer": """
    ä½ æ˜¯ä¸€åã€å­¦æœ¯æœŸåˆŠå®¡ç¨¿äººã€‘ã€‚
    
    ã€å¾…å®¡é˜…ç¨¿ä»¶ã€‘
    {draft}
    
    è¯·ä¸¥æ ¼è¯„å®¡è¿™ä»½æŠ¥å‘Šã€‚
    1. æ˜¯å¦åŒ…å«å…·ä½“æ•°æ®æ”¯æŒï¼Ÿ
    2. é€»è¾‘æ˜¯å¦é€šé¡ºï¼Ÿ
    3. æ ¼å¼æ˜¯å¦è§„èŒƒï¼Ÿ
    
    è¯·è¾“å‡ºæ ‡å‡† JSONï¼ˆä¸¥ç¦ Markdownï¼‰ï¼š
    {{
        "status": "PASS" æˆ– "FAIL",
        "comments": "è¯¦ç»†çš„è¯„å®¡æ„è§",
        "revised_content": "å¦‚æœåªæœ‰å°é—®é¢˜ï¼Œè¯·ç›´æ¥æä¾›æ¶¦è‰²åçš„å…¨æ–‡ï¼›å¦‚æœé—®é¢˜ä¸¥é‡åˆ¤FAILï¼Œæ­¤å­—æ®µç•™ç©ºã€‚"
    }}
    """
}

def call_agent_llm(provider, api_key, model_config, prompt):
    if not api_key: return f"Error: ç¼ºå°‘ {provider} çš„ API Key"
    
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
    payload = {
        "model": model_config[provider]["model"],
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.1 # ä¿æŒä½æ¸©åº¦ä»¥è·å¾—ç¨³å®šè¾“å‡º
    }
    try:
        resp = requests.post(model_config[provider]["url"], headers=headers, json=payload, timeout=120)
        if resp.status_code != 200:
            return f"Error: APIè°ƒç”¨å¤±è´¥ ({resp.status_code}) - {resp.text}"
        return resp.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"Error: è¯·æ±‚å¼‚å¸¸ - {str(e)}"

# --- æ ¸å¿ƒ 1ï¼šæ±‚è§£é—­ç¯ (Chat Mode) ---
def run_expert_loop(user_query, data_context, api_keys, model_config, execute_callback, df):
    roles = {"planner": "deepseek", "executor": "qwen", "verifier": "zhipu"}
    
    available_keys = [k for k, v in api_keys.items() if v]
    if not available_keys: return {"error": "æœªé…ç½®ä»»ä½• API Key", "process_log": "âŒ æ—  Key"}
    for r in roles: 
        if not api_keys.get(roles[r]): roles[r] = available_keys[0]

    process_log = []
    iteration = 0
    max_iterations = 3 # å…è®¸æœ€å¤š3æ¬¡å°è¯•
    feedback = ""

    while iteration < max_iterations:
        iter_prefix = f"#### [ç¬¬ {iteration + 1} è½®è¿­ä»£]"
        
        # 1. è§„åˆ’
        if iteration == 0:
            # é¦–è½®è§„åˆ’
            process_log.append(f"{iter_prefix}\n**ğŸ§  æ¶æ„å¸ˆ ({roles['planner']}) æ­£åœ¨è§„åˆ’...**")
            plan_prompt = PROMPTS["planner"].format(user_query=user_query, data_context=data_context, feedback_context="")
        else:
            # åŸºäºåé¦ˆé‡æ–°è§„åˆ’ (æˆ–è€…è·³è¿‡è§„åˆ’ç›´æ¥ä¿®ä»£ç ï¼Œè¿™é‡Œç®€åŒ–ä¸ºé‡æ–°è§„åˆ’ä»¥ç¡®ä¿ä¸€è‡´æ€§)
            process_log.append(f"{iter_prefix}\n**ğŸ§  æ¶æ„å¸ˆ ({roles['planner']}) æ ¹æ®åé¦ˆè°ƒæ•´è“å›¾...**")
            plan_prompt = PROMPTS["planner"].format(user_query=user_query, data_context=data_context, feedback_context=f"ã€ä¸Šä¸€è½®å¤±è´¥åŸå› ã€‘ï¼š{feedback}")

        plan = call_agent_llm(roles["planner"], api_keys[roles["planner"]], model_config, plan_prompt)
        if plan.startswith("Error"): return {"error": plan, "process_log": "\n".join(process_log)}
        
        process_log.append(f"> **è“å›¾æ‘˜è¦**ï¼š\n{plan[:200]}...\n")

        # 2. æ‰§è¡Œ
        process_log.append(f"**ğŸ’» ç¨‹åºå‘˜ ({roles['executor']}) æ­£åœ¨ç¼–ç ...**")
        code_res = call_agent_llm(roles["executor"], api_keys[roles["executor"]], model_config, 
                                  PROMPTS["executor"].format(plan=plan, data_context=data_context))
        
        code_match = re.search(r"```python(.*?)```", code_res, re.DOTALL)
        code = code_match.group(1).strip() if code_match else code_res
        
        process_log.append(f"**âš™ï¸ ç³»ç»Ÿè¿è¡Œä»£ç ä¸­...**")
        exec_text, exec_img, new_df = execute_callback(code, df)
        
        # é”™è¯¯é¢„æ£€
        error_flag = False
        if exec_text.startswith("Error") or "Traceback" in exec_text:
             error_flag = True
             process_log.append(f"âš ï¸ **è¿è¡Œæ—¶é”™è¯¯æ£€æµ‹åˆ°**ï¼š`{exec_text[:100]}...`")
        
        # 3. éªŒè¯
        process_log.append(f"**âš–ï¸ è¯„å®¡å‘˜ ({roles['verifier']}) æ­£åœ¨å®¡æ ¸...**")
        
        # å¦‚æœæœ‰é”™ï¼Œå¼ºåˆ¶æç¤ºè¯„å®¡å‘˜
        force_fail_prompt = "\n\nâš ï¸ã€ç³»ç»Ÿæ£€æµ‹åˆ°è¿è¡ŒæŠ¥é”™ã€‘ï¼šè¯·åŠ¡å¿…åˆ¤ä¸º FAIL å¹¶åˆ†ææŠ¥é”™åŸå› ï¼" if error_flag else ""
        
        verify_res = call_agent_llm(roles["verifier"], api_keys[roles["verifier"]], model_config, 
                                    PROMPTS["verifier"].format(plan=plan, code=code, execution_result=exec_text) + force_fail_prompt)
        
        review = extract_and_parse_json(verify_res)
        
        if not review:
            # JSON è§£æå¤±è´¥ï¼Œä¿é™©èµ·è§ï¼Œå¦‚æœä»£ç æ²¡æŠ¥é”™å°±é€šè¿‡ï¼ŒæŠ¥é”™å°±é‡è¯•
            if error_flag:
                process_log.append("âŒ è¯„å®¡å‘˜è¾“å‡ºæ ¼å¼é”™è¯¯ä¸”ä»£ç æŠ¥é”™ï¼Œå¼ºåˆ¶é‡è¯•ã€‚")
                feedback = "ä»£ç è¿è¡ŒæŠ¥é”™ï¼Œä¸”è¯„å®¡å‘˜æœªè¿”å›æœ‰æ•ˆ JSONã€‚è¯·ä¿®å¤ä»£ç é”™è¯¯ã€‚"
                iteration += 1
                continue
            else:
                process_log.append("âš ï¸ è¯„å®¡å‘˜è¾“å‡ºæ ¼å¼å¼‚å¸¸ï¼Œä½†åœ¨æ— æŠ¥é”™æƒ…å†µä¸‹é»˜è®¤é€šè¿‡ã€‚")
                review = {"status": "PASS", "reason": "æ ¼å¼è§£æå¤±è´¥ä½†ä»£ç è¿è¡Œæ— è¯¯"}

        if review.get("status") == "PASS":
            process_log.append(f"âœ… **éªŒè¯é€šè¿‡**: {review.get('reason')}")
            return {
                "reply": f"### ğŸ¯ Radarm ä¸“å®¶æŠ¥å‘Š\n\n**1. åˆ†æè“å›¾**\n{plan}\n\n**2. æ‰§è¡Œç»“æœ**\n{exec_text}\n\n**3. ä¸“å®¶è¯„å®¡**\n{review.get('reason')}",
                "generated_code": code,
                "execution_result": exec_text,
                "image": exec_img,
                "new_df": new_df,
                "process_log": "\n".join(process_log)
            }
        else:
            process_log.append(f"âŒ **éªŒè¯ä¸é€šè¿‡**: {review.get('reason')}")
            process_log.append(f"ğŸ”„ **ä¿®æ”¹å»ºè®®**: {review.get('suggestion')}")
            feedback = review.get('suggestion')
            iteration += 1
            
    return {
        "reply": f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({max_iterations})ã€‚æœ€åä¸€æ¬¡å°è¯•æœªé€šè¿‡éªŒè¯ã€‚\n**é”™è¯¯ä¿¡æ¯**: {exec_text}",
        "generated_code": code,
        "execution_result": exec_text,
        "image": exec_img,
        "new_df": new_df,
        "process_log": "\n".join(process_log)
    }

# --- æ ¸å¿ƒ 2: æŠ¥å‘Šç”Ÿæˆé—­ç¯ (Report Mode) ---
def generate_expert_report(data_info, data_desc, data_sample, api_keys, model_config):
    roles = {"architect": "deepseek", "writer": "qwen", "reviewer": "zhipu"}
    
    available_keys = [k for k, v in api_keys.items() if v]
    if not available_keys: return {"error": "æœªé…ç½® API Key", "log": "âŒ æ—  Key"}
    for r in roles: 
        if not api_keys.get(roles[r]): roles[r] = available_keys[0]

    process_log = []
    
    # 1. æ¶æ„
    process_log.append(f"### ğŸš€ æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å¯åŠ¨\n")
    process_log.append(f"**ğŸ§  å­¦æœ¯é¡¾é—® ({roles['architect']}) è®¾è®¡å¤§çº²...**")
    outline = call_agent_llm(roles["architect"], api_keys[roles["architect"]], model_config, REPORT_PROMPTS["architect"].format(data_info=data_info))
    if outline.startswith("Error"): return {"error": outline, "log": "\n".join(process_log)}
    process_log.append(f"> **å¤§çº²å·²ç”Ÿæˆ**\n")
    
    # 2. æ’°å†™ä¸è¿­ä»£å¾ªç¯
    current_feedback = ""
    iteration = 0
    max_iterations = 2
    final_content = ""
    
    while iteration < max_iterations:
        iter_prefix = f"#### [ç¬¬ {iteration + 1} è½®æ’°å†™]"
        
        # æ’°å†™
        process_log.append(f"{iter_prefix}\n**âœï¸ æ’°ç¨¿äºº ({roles['writer']}) æ’°å†™/ä¿®æ”¹ä¸­...**")
        draft_prompt = REPORT_PROMPTS["writer"].format(
            outline=outline, 
            data_desc=data_desc, 
            data_sample=data_sample,
            feedback=current_feedback if current_feedback else "æ— "
        )
        draft = call_agent_llm(roles["writer"], api_keys[roles["writer"]], model_config, draft_prompt)
        if draft.startswith("Error"): return {"error": draft, "log": "\n".join(process_log)}
        
        process_log.append(f"**âš–ï¸ å®¡ç¨¿äºº ({roles['reviewer']}) æ­£åœ¨è¯„å®¡...**")
        review_res = call_agent_llm(roles["reviewer"], api_keys[roles["reviewer"]], model_config, REPORT_PROMPTS["reviewer"].format(draft=draft))
        
        review = extract_and_parse_json(review_res)
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¯´æ˜å®¡ç¨¿äººå¯èƒ½ç›´æ¥è¿”å›äº†æ¶¦è‰²åçš„æ–‡ç« ï¼ˆé JSON æ ¼å¼ï¼‰ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ç§ PASS
        if not review:
            # ç®€å•åˆ¤æ–­ï¼šå¦‚æœæ˜¯é•¿æ–‡æœ¬ä¸”æ²¡æœ‰ Errorï¼Œå°±å½“åšæ˜¯æ¶¦è‰²åçš„æ–‡ç« 
            if len(review_res) > 100 and not review_res.startswith("Error"):
                process_log.append("âœ… å®¡ç¨¿äººç›´æ¥è¿”å›äº†æ¶¦è‰²ç¨¿ï¼Œæµç¨‹ç»“æŸã€‚")
                final_content = review_res
                break
            else:
                process_log.append("âš ï¸ å®¡ç¨¿äººè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œé»˜è®¤é‡‡ç”¨å½“å‰åˆç¨¿ã€‚")
                final_content = draft
                break
        
        if review.get("status") == "PASS":
            process_log.append(f"âœ… **å®¡ç¨¿é€šè¿‡**: {review.get('comments')}")
            # å¦‚æœæœ‰æ¶¦è‰²å†…å®¹å°±ç”¨æ¶¦è‰²å†…å®¹ï¼Œå¦åˆ™ç”¨åŸç¨¿
            final_content = review.get("revised_content") if review.get("revised_content") else draft
            break
        else:
            process_log.append(f"âŒ **å®¡ç¨¿æœªé€šè¿‡**: {review.get('comments')}")
            current_feedback = review.get('comments')
            iteration += 1
            if iteration == max_iterations:
                process_log.append("âš ï¸ è¾¾åˆ°æœ€å¤§ä¿®æ”¹æ¬¡æ•°ï¼Œå¼ºåˆ¶å®šç¨¿ã€‚")
                final_content = draft # æ²¡è¿‡ä¹Ÿåªèƒ½äº¤äº†

    return {
        "content": final_content,
        "log": "\n".join(process_log)
    }