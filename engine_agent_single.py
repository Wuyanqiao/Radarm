"""
å•æ¨¡å‹ Agent å¼•æ“ï¼ˆåº•å±‚èƒ½åŠ›ï¼‰
----------------------------
ç”¨äºâ€œç”¨æˆ·èŠå¤© Radarm AI agent çš„å•æ¨¡å‹æ¨¡å¼â€ã€‚

èŒè´£ï¼š
1) å•æ¨¡å‹ç”Ÿæˆ Python ä»£ç ï¼ˆé¢å‘ DataFrame `df`ï¼‰
2) é€šè¿‡åç«¯æä¾›çš„ execute_callback(code, df) åœ¨æ²™ç›’æ‰§è¡Œ
3) å†æ¬¡è°ƒç”¨åŒä¸€æ¨¡å‹ç”Ÿæˆç®€è¦è§£é‡Š

ä¸è´Ÿè´£ï¼š
- FastAPI è·¯ç”±ä¸ Session çŠ¶æ€ï¼ˆè§ backend.pyï¼‰
"""

import re
import importlib
from typing import Any, Dict, Optional, List

PROMPT_TEMPLATE = """
ä½ æ˜¯ Python æ•°æ®åˆ†æä¸“å®¶ã€‚
è¿è¡Œç¯å¢ƒä¸­å·²æœ‰ DataFrame `df`ï¼ˆå†…å­˜æ•°æ®ï¼‰ï¼Œä¸¥ç¦è¯»å–ä»»ä½•å¤–éƒ¨æ–‡ä»¶/ç½‘ç»œï¼ˆä¸è¦ read_csv/read_excelï¼Œä¸è¦ data.csvï¼Œä¸è¦ requestsï¼‰ã€‚
ç”¨æˆ·éœ€æ±‚ï¼š{user_query}
æ•°æ®æ¦‚å†µï¼š{data_context}

ã€é‡è¦æç¤º - å›¾ç‰‡å’Œè§†è§‰ç†è§£æ•°æ®ã€‘
å¦‚æœä¸Šé¢çš„"æ•°æ®æ¦‚å†µ"ä¸­åŒ…å«"[è§†è§‰ç†è§£]"æˆ–"[å›¾ç‰‡é™„ä»¶]"éƒ¨åˆ†ï¼š
1. **å®Œæ•´ç†è§£å›¾ç‰‡ä¿¡æ¯**ï¼šä»”ç»†é˜…è¯»è§†è§‰ç†è§£ç»“æœï¼Œç†è§£å›¾ç‰‡ä¸­çš„æ‰€æœ‰ä¿¡æ¯ï¼ˆæ–‡å­—ã€è¡¨æ ¼ã€å›¾è¡¨ã€æ ‡å‡†ã€è§„èŒƒã€ç•Œé¢å…ƒç´ ã€å›¾åƒå†…å®¹ç­‰ï¼‰
2. **æå–å¹¶ä½¿ç”¨å›¾ç‰‡ä¿¡æ¯**ï¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œè§†è§‰ç†è§£ç»“æœï¼Œæå–å›¾ç‰‡ä¸­çš„ä»»ä½•ç›¸å…³ä¿¡æ¯å¹¶åœ¨ä»£ç ä¸­ä½¿ç”¨
3. **ç»“æ„åŒ–æ•°æ®å®šä¹‰**ï¼šå¦‚æœå›¾ç‰‡åŒ…å«è¡¨æ ¼ã€æ ‡å‡†ã€è§„èŒƒã€é™å€¼ç­‰ç»“æ„åŒ–ä¿¡æ¯ï¼Œä¸”ä»£ç ä¸­éœ€è¦ä½¿ç”¨è¿™äº›ä¿¡æ¯ï¼Œ**å¿…é¡»åœ¨ä»£ç å¼€å¤´å…ˆè§£æå¹¶å®šä¹‰ç›¸åº”çš„æ•°æ®ç»“æ„**ï¼ˆå¦‚å­—å…¸ã€DataFrameã€åˆ—è¡¨ç­‰ï¼‰
4. **ç¤ºä¾‹**ï¼š
   - å¦‚æœè§†è§‰ç†è§£æåˆ°æ ‡å‡†é™å€¼ï¼ˆå¦‚"æ€»é…¸â‰¥0.4ï¼ˆä¼˜çº§ï¼‰"ï¼‰ï¼Œåº”åˆ›å»ºç±»ä¼¼ `standards = {{'æ€»é…¸': {{'ä¼˜çº§': 0.4, 'ä¸€çº§': 0.3}}}}` çš„ç»“æ„
   - å¦‚æœè§†è§‰ç†è§£æåˆ°è¡¨æ ¼æ•°æ®ï¼Œåº”åˆ›å»ºç›¸åº”çš„DataFrameæˆ–å­—å…¸ç»“æ„
   - å¦‚æœè§†è§‰ç†è§£æåˆ°å…¶ä»–ç»“æ„åŒ–ä¿¡æ¯ï¼Œåº”æ ¹æ®éœ€è¦åˆ›å»ºç›¸åº”çš„æ•°æ®ç»“æ„
5. **é¿å…ç¡¬ç¼–ç **ï¼šç¡®ä¿ä»£ç ä¸­ä½¿ç”¨çš„å›¾ç‰‡ä¿¡æ¯éƒ½ä»è§†è§‰ç†è§£ç»“æœä¸­æå–å¹¶å®šä¹‰ï¼Œè€Œä¸æ˜¯ç›´æ¥ç¡¬ç¼–ç æˆ–å¼•ç”¨æœªå®šä¹‰çš„å˜é‡
6. **å……åˆ†åˆ©ç”¨æ‰€æœ‰ä¿¡æ¯**ï¼šä¸è¦åªå…³æ³¨è¡¨æ ¼æˆ–æ ‡å‡†ï¼Œè¦å……åˆ†åˆ©ç”¨å›¾ç‰‡ä¸­çš„ä»»ä½•ç›¸å…³ä¿¡æ¯ï¼ˆæ–‡å­—è¯´æ˜ã€å›¾è¡¨è¶‹åŠ¿ã€ç•Œé¢çŠ¶æ€ç­‰ï¼‰

ã€è§„åˆ™ã€‘
1. æœºå™¨å­¦ä¹ ä»»åŠ¡å¿…é¡»è°ƒç”¨ `ml.run(df, ...)`ã€‚
2. æ™®é€šåˆ†æå¯ç”¨ pandas/numpy/matplotlib/seabornã€‚
3. å…³é”®ç»“è®ºå¿…é¡»èµ‹å€¼ç»™å˜é‡ `result`ï¼ˆå­—ç¬¦ä¸²æˆ–æ•°å€¼å‡å¯ï¼‰ã€‚
4. ç»˜å›¾ä¸è¦è°ƒç”¨ `plt.show()`ã€‚
5. åªè¾“å‡ºä¸€ä¸ª ```python ä»£ç å—ï¼Œä¸è¦è§£é‡Šã€‚
"""


def _call_llm(provider: str, api_key: str, model_config: Dict[str, Any], prompt: str) -> Optional[str]:
    if not api_key:
        return None
    cfg = model_config.get(provider)
    if not cfg:
        return None

    try:
        requests = importlib.import_module("requests")
    except Exception:
        return None

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
    payload = {"model": cfg["model"], "messages": [{"role": "user", "content": prompt}], "temperature": 0.1}
    try:
        resp = requests.post(cfg["url"], headers=headers, json=payload, timeout=60)
        if resp.status_code != 200:
            return None
        return resp.json()["choices"][0]["message"]["content"]
    except Exception:
        return None


def _extract_python_code(ai_response: str) -> str:
    m = re.search(r"```python(.*?)```", ai_response, re.DOTALL | re.IGNORECASE)
    return m.group(1).strip() if m else ai_response.strip()

def _auto_feedback_from_exec(exec_text: Any) -> str:
    t = str(exec_text or "")
    if not t:
        return ""
    if "No such file or directory" in t or "FileNotFoundError" in t:
        return "ä¸è¦è¯»å–ä»»ä½•æœ¬åœ°æ–‡ä»¶ï¼ˆå¦‚ data.csvï¼‰ã€‚è¿è¡Œç¯å¢ƒå·²æä¾› dfï¼Œè¯·ç›´æ¥ä½¿ç”¨ df è¿›è¡Œåˆ†æã€‚"
    if "KeyError" in t:
        return "å‡ºç° KeyErrorï¼ˆåˆ—åä¸å­˜åœ¨ï¼‰ã€‚è¯·æ£€æŸ¥ df.columnsï¼Œå¿…è¦æ—¶åšåˆ—åæ¨¡ç³ŠåŒ¹é…ï¼Œå¹¶åœ¨ä»£ç ä¸­å¤„ç†åˆ—ä¸å­˜åœ¨çš„æƒ…å†µï¼ˆç»™å‡ºæ˜ç¡®æç¤ºï¼‰ã€‚"
    if "ç¦æ­¢æ–‡ä»¶/ç½‘ç»œ/ç³»ç»Ÿæ“ä½œ" in t:
        return "ç³»ç»Ÿç¦æ­¢æ–‡ä»¶/ç½‘ç»œ/ç³»ç»Ÿæ“ä½œã€‚è¯·ç§»é™¤ read_csv/read_excel/open/requests ç­‰ï¼Œç›´æ¥ä½¿ç”¨ df è¿›è¡Œè®¡ç®—ã€‚"
    return ""


def run_single_agent_engine(
    *,
    user_query: str,
    data_context: str = "",
    api_keys: Dict[str, str],
    primary_model: str,
    model_config: Dict[str, Any],
    execute_callback,
    df,
) -> Dict[str, Any]:
    """
    å•æ¨¡å‹ Agent å¼•æ“å…¥å£ï¼ˆä¾› workflow_single_chat.py è°ƒç”¨ï¼‰
    """
    api_key = api_keys.get(primary_model)
    if not api_key:
        return {"error": f"æœªé…ç½® {primary_model} çš„ API Key", "process_log": f"âŒ missing_key provider={primary_model}"}

    process_log: List[str] = []
    max_attempts = 2
    code = ""
    exec_text, exec_img, plotly_json, new_df = "", None, None, None

    for attempt in range(1, max_attempts + 1):
        # 1) ç”Ÿæˆä»£ç ï¼ˆæ³¨å…¥æ•°æ®æ¦‚å†µï¼‰
        prompt = PROMPT_TEMPLATE.format(user_query=user_query, data_context=(data_context or ""))
        if attempt > 1:
            prompt = (
                prompt
                + "\n\nã€ä¸Šä¸€è½®æ‰§è¡Œå¤±è´¥åé¦ˆã€‘\n"
                + (_auto_feedback_from_exec(exec_text) or "è¯·æ ¹æ®æŠ¥é”™ä¿®å¤ä»£ç ï¼Œå¹¶ç¡®ä¿ result æœ‰è¾“å‡ºã€‚")
                + "\n\nã€ä¸Šä¸€è½®é”™è¯¯ã€‘\n"
                + (str(exec_text)[:2000] + ("...(æˆªæ–­)" if len(str(exec_text)) > 2000 else ""))
                + "\n\nè¯·è¾“å‡ºä¿®å¤åçš„å®Œæ•´ Python ä»£ç å—ï¼ˆ```python ...```ï¼‰ï¼ŒåŠ¡å¿…å¯æ‰§è¡Œã€‚"
            )

        process_log.append(f"#### [å•æ¨¡å‹] ç¬¬ {attempt} æ¬¡ç”Ÿæˆä»£ç ï¼ˆ{primary_model}ï¼‰")
        ai_response = _call_llm(primary_model, api_key, model_config, prompt)
        if not ai_response:
            return {"error": "AI æ— å“åº”æˆ–è¯·æ±‚è¶…æ—¶", "process_log": "\n".join(process_log)}

        # 2) æ‰§è¡Œä»£ç 
        code = _extract_python_code(ai_response)
        process_log.append("**âš™ï¸ æ‰§è¡Œä»£ç ...**")
        # æ”¯æŒæ–°çš„4å…ƒç»„è¿”å›ï¼š (output_text, image_path, plotly_json, new_df)
        result = execute_callback(code, df)
        if len(result) == 4:
            exec_text, exec_img, plotly_json, new_df = result
        else:
            # å‘åå…¼å®¹ï¼šå¦‚æœæ˜¯3å…ƒç»„ï¼Œæ·»åŠ  None ä½œä¸º plotly_json
            exec_text, exec_img, new_df = result
            plotly_json = None

        has_error = isinstance(exec_text, str) and (
            exec_text.startswith("Error") or "Traceback" in exec_text or "Exception" in exec_text
        )
        if not has_error:
            break
        process_log.append(f"âš ï¸ **æŠ¥é”™**: {str(exec_text)[:200]}")
        if attempt < max_attempts:
            fb = _auto_feedback_from_exec(exec_text)
            if fb:
                process_log.append(f"ğŸ¤– **ç³»ç»Ÿæç¤º**: {fb}")

    # 3) ç”Ÿæˆè§£é‡Šï¼ˆé¿å…æŠŠè¶…é•¿æ‰§è¡Œè¾“å‡ºå¡å›æ¨¡å‹ï¼‰
    exec_text_for_explain = exec_text
    if isinstance(exec_text_for_explain, str) and len(exec_text_for_explain) > 2000:
        exec_text_for_explain = exec_text_for_explain[:2000] + "...(æˆªæ–­)"
    explain_prompt = (
        f"ç”¨æˆ·éœ€æ±‚ï¼š{user_query}\n"
        f"æ•°æ®æ¦‚å†µï¼š{(data_context or '')[:6000]}\n\n"
        f"ä»£ç æ‰§è¡Œç»“æœï¼š{exec_text_for_explain}\n\n"
        "è¯·ç”¨ä¸­æ–‡ç®€è¦è§£é‡Šåˆ†æç»“æœï¼Œå¹¶ç»™å‡ºä¸‹ä¸€æ­¥å»ºè®®ï¼ˆä¸è¦æœæ’°æ•°æ®ï¼‰ã€‚"
    )
    explain_res = _call_llm(primary_model, api_key, model_config, explain_prompt)

    return {
        "reply": explain_res if explain_res else "æ‰§è¡Œå®Œæˆï¼ˆAIæœªè¿”å›è§£é‡Šï¼‰",
        "generated_code": code,
        "execution_result": exec_text,
        "image": exec_img,
        "plotly_json": plotly_json,  # æ–°å¢ï¼šPlotly å›¾è¡¨ JSON
        "new_df": new_df,
        "process_log": "\n".join(process_log),
    }


